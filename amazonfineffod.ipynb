{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1000_Amazon_review_anusha.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0007SVD9M</td>\n",
       "      <td>ATDTM14U5KFVT</td>\n",
       "      <td>Keith Hough</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>They changed the flavor and it is not good.</td>\n",
       "      <td>I've been ordering cases of Altoids for years ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B002HFWMOI</td>\n",
       "      <td>A2O0JY6777FXXU</td>\n",
       "      <td>Michelle</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Positive Review</td>\n",
       "      <td>Good, but Amazon has the flavor names wrong</td>\n",
       "      <td>Flavor names vs flavor photos are pretty confu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B002ACQHDA</td>\n",
       "      <td>AS0SPE5TEM74Z</td>\n",
       "      <td>Elizabeth Kingsley</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive Review</td>\n",
       "      <td>Excellent flavor.</td>\n",
       "      <td>Actually does taste like creme brulee.  Makes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B004XTDMOA</td>\n",
       "      <td>A37QTP674OKCU</td>\n",
       "      <td>Michael A. Cutting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>Crap</td>\n",
       "      <td>I normally buy maruchan ramen and just add cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B004YV80OE</td>\n",
       "      <td>A2QR043WBXXX6L</td>\n",
       "      <td>Stephen Cunningham</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>Broccoli in this?  Really?</td>\n",
       "      <td>Well, I have to admit to being very disappoint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B0059YB39O</td>\n",
       "      <td>A93AG3JQQVXOZ</td>\n",
       "      <td>R. Valley</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>Regular is Salty--Peppered is Great</td>\n",
       "      <td>I would say I get less salt from sucking on a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B001BS4G6O</td>\n",
       "      <td>AM76TKHVICZC6</td>\n",
       "      <td>Gertrud Kahler</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive Review</td>\n",
       "      <td>mmm, mmmm, good!</td>\n",
       "      <td>My dog loves these. Totally unaware that she i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B003N0ZEKU</td>\n",
       "      <td>A2GRVML0NK37PQ</td>\n",
       "      <td>Dora C. Zuses</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive Review</td>\n",
       "      <td>yummy butter toffee</td>\n",
       "      <td>Really good coffe tasty not to strong since I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B002LANN56</td>\n",
       "      <td>A1JISH2AQDW1YW</td>\n",
       "      <td>QueenKatieMae</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>Dog rating: 5 stars. Human rating: 1 star.</td>\n",
       "      <td>My dog devoured this stuff like she was starve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00455QA00</td>\n",
       "      <td>A2DNWHJR198MKZ</td>\n",
       "      <td>hupi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>Worst Smell</td>\n",
       "      <td>I was very disappointed with this product. The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B000I3UZJA</td>\n",
       "      <td>A1D7B5FIFWRE9Q</td>\n",
       "      <td>Tanya Scott</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Negative Review</td>\n",
       "      <td>Smoked the house more than the food</td>\n",
       "      <td>I bought this item based on such good reviews....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId         ProfileName  HelpfulnessNumerator  \\\n",
       "0   B0007SVD9M   ATDTM14U5KFVT         Keith Hough                     1   \n",
       "1   B002HFWMOI  A2O0JY6777FXXU            Michelle                     3   \n",
       "2   B002ACQHDA   AS0SPE5TEM74Z  Elizabeth Kingsley                     0   \n",
       "3   B004XTDMOA   A37QTP674OKCU  Michael A. Cutting                     0   \n",
       "4   B004YV80OE  A2QR043WBXXX6L  Stephen Cunningham                     3   \n",
       "5   B0059YB39O   A93AG3JQQVXOZ           R. Valley                     0   \n",
       "6   B001BS4G6O   AM76TKHVICZC6      Gertrud Kahler                     0   \n",
       "7   B003N0ZEKU  A2GRVML0NK37PQ       Dora C. Zuses                     0   \n",
       "8   B002LANN56  A1JISH2AQDW1YW       QueenKatieMae                     3   \n",
       "9   B00455QA00  A2DNWHJR198MKZ                hupi                     0   \n",
       "10  B000I3UZJA  A1D7B5FIFWRE9Q         Tanya Scott                     1   \n",
       "\n",
       "    HelpfulnessDenominator            Score  \\\n",
       "0                        1  Negative Review   \n",
       "1                        3  Positive Review   \n",
       "2                        0  Positive Review   \n",
       "3                        0  Negative Review   \n",
       "4                        4  Negative Review   \n",
       "5                        0  Negative Review   \n",
       "6                        0  Positive Review   \n",
       "7                        0  Positive Review   \n",
       "8                        3  Negative Review   \n",
       "9                        0  Negative Review   \n",
       "10                       4  Negative Review   \n",
       "\n",
       "                                        Summary  \\\n",
       "0   They changed the flavor and it is not good.   \n",
       "1   Good, but Amazon has the flavor names wrong   \n",
       "2                             Excellent flavor.   \n",
       "3                                          Crap   \n",
       "4                    Broccoli in this?  Really?   \n",
       "5           Regular is Salty--Peppered is Great   \n",
       "6                              mmm, mmmm, good!   \n",
       "7                           yummy butter toffee   \n",
       "8    Dog rating: 5 stars. Human rating: 1 star.   \n",
       "9                                   Worst Smell   \n",
       "10          Smoked the house more than the food   \n",
       "\n",
       "                                                 Text  \n",
       "0   I've been ordering cases of Altoids for years ...  \n",
       "1   Flavor names vs flavor photos are pretty confu...  \n",
       "2   Actually does taste like creme brulee.  Makes ...  \n",
       "3   I normally buy maruchan ramen and just add cur...  \n",
       "4   Well, I have to admit to being very disappoint...  \n",
       "5   I would say I get less salt from sucking on a ...  \n",
       "6   My dog loves these. Totally unaware that she i...  \n",
       "7   Really good coffe tasty not to strong since I'...  \n",
       "8   My dog devoured this stuff like she was starve...  \n",
       "9   I was very disappointed with this product. The...  \n",
       "10  I bought this item based on such good reviews....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(cleanhtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductId                 False\n",
       "UserId                    False\n",
       "ProfileName               False\n",
       "HelpfulnessNumerator      False\n",
       "HelpfulnessDenominator    False\n",
       "Score                     False\n",
       "Summary                   False\n",
       "Text                      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2000 rows and 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-455680ca2399>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-455680ca2399>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_data = df[df['Score']=='Negative Review']['Summary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(''.join(negative_reviews_data))\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews_data = df[df['Score']=='Positive Review']['Text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud().generate(''.join(positive_reviews_data))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicates in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>HelpfulnessNumerator:</b><br> count is 2000.000000 <br>\n",
    "                          mean is 2.235500 <br>\n",
    "                          std is 10.491381 <br>\n",
    "                          min is 0.000000   <br>\n",
    "                          25% is 0.000000   <br>\n",
    "                          50% is 1.000000   <br>\n",
    "                          75% is 2.000000    <br>\n",
    "                          max is 406.000000   <br>\n",
    "                     \n",
    "<b>HelpfulnessDenominator:</b> <br> count is 2000.000000 <br>\n",
    "                                    mean is 3.543500   <br>\n",
    "                                    std is 11.730171   <br>\n",
    "                                    min is 0.000000    <br>\n",
    "                                    25% is 0.000000    <br>\n",
    "                                     50% is 1.000000    <br>\n",
    "                                     75% is 4.000000    <br>\n",
    "                                      max is 415.000000    <br>\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column1 =df[\"HelpfulnessNumerator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(column1.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column2 =df[\"HelpfulnessDenominator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.distplot(column2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are outliers in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df[[\"ProductId\", \"UserId\", \"ProfileName\", \"HelpfulnessNumerator\", \"HelpfulnessDenominator\", \"Summary\", \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df[[\"Score\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "\n",
    "x_train = vec.fit_transform(x_train[\"Text\"].values)\n",
    "x_test = vec.transform(x_test[\"Text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,y_train.shape[0]):\n",
    "    if(y_train[i]==\"Negative Review\"):\n",
    "        y_train[i] = 0\n",
    "    else:\n",
    "        y_train[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,y_test.shape[0]):\n",
    "    if(y_test[i]==\"Negative Review\"):\n",
    "        y_test[i] = 0\n",
    "    else:\n",
    "        y_test[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train,y_train.astype(int).ravel())\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(pred,y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Accuracy of the model is :\",acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(pred,y_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decison Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "model.fit(x_train,y_train.astype(int))\n",
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(pred,y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The Accuracy of the model is :\",acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(pred,y_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN(Artifical Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = tf.one_hot(y_train, depth=2).numpy()[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.Dense(64))\n",
    "model.add(tf.keras.layers.Dense(32))\n",
    "model.add(tf.keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Prd = model.predict(x_test.toarray().astype(int))\n",
    "\n",
    "prd = [1 if x>0.5 else 0 for x in Prd]\n",
    "# Prd = np.argmax(Prd,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr= accuracy_score(prd,y_test.astype(int))\n",
    "print(\"The Accuracy of the model is :\",accr*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(prd,y_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "myTable = PrettyTable([\"Model Name\", \"Accuracy\", \"True Positives\", \"True Negatives\"])\n",
    "  \n",
    "myTable.add_row([\"Logistic Regression\", \"82.6%\", \"211\", \"201\"])\n",
    "myTable.add_row([\"Decision Tree Classifier\", \"71.6%\", \"191\", \"167\"])\n",
    "myTable.add_row([\"ANN\", \"84.8%\", \"215\", \"209\"])\n",
    "\n",
    "  \n",
    "print(myTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from datetime import datetime\n",
    "start = str(datetime.now())\n",
    "def build_classifier(optimizer, nh1, nh2, nh3):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = nh1, kernel_initializer = 'uniform', activation = 'relu', input_dim = 1677))\n",
    "    classifier.add(Dense(units = nh2, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = nh3, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['auc_score'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'optimizer': ['adam','rmsprop'],\n",
    "             'nh1' : [256, 128, 64],\n",
    "             'nh2' : [128, 64, 32],\n",
    "             'nh3' : [64, 32, 16]}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                          param_grid = parameters,\n",
    "                          scoring = 'accuracy',\n",
    "                          cv = 3)\n",
    "grid_search = grid_search.fit(x_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "end = str(datetime.now())\n",
    "print('Start time:  ' + start)\n",
    "print('End time:  ' + end)\n",
    "                         \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
